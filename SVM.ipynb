{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries and and global variables\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cvxopt import matrix, solvers\n",
    "\n",
    "K = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Loading dataset for classification, scale and split test and train\n",
    "iris = datasets.load_iris()\n",
    "# Filter and conserve tipe 0 and 2 of iris\n",
    "cond = (iris.target != 1)\n",
    "# Preprocess dataset to be used in SVM\n",
    "y = iris.target[cond] - 1\n",
    "y = y.astype('float')\n",
    "x = iris.data[cond].astype('float')\n",
    "x = preprocessing.scale(x)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 1\n",
    "\n",
    "# Custom rbf kernel\n",
    "def krbf(x,y,sigma):\n",
    "    return np.exp(-np.linalg.norm(x - y)**2/(2*sigma**2))\n",
    "\n",
    "# SVM with rbf kernel\n",
    "def fitNonLinear(x, y): \n",
    "    global K\n",
    "    NUM = x.shape[0]\n",
    "    DIM = x.shape[1]\n",
    "    \n",
    "    Y = np.reshape(y, (NUM, 1))\n",
    "    Ym = np.matmul(Y,Y.T)\n",
    "    # we'll solve the dual\n",
    "    # obtain the kernel\n",
    "    K = np.zeros((NUM,NUM))\n",
    "    for i in range(NUM):\n",
    "        for j in range(NUM):\n",
    "            K[i,j] = krbf(x[i], x[j], sigma)\n",
    "    K = np.multiply(K, Ym)\n",
    "    P = matrix(K)\n",
    "    q = matrix(-np.ones((NUM, 1)))\n",
    "    G = matrix(-np.eye(NUM))\n",
    "    h = matrix(np.zeros(NUM))\n",
    "    A = matrix(y.reshape(1, -1))\n",
    "    b = matrix(np.zeros(1))\n",
    "    solvers.options['show_progress'] = False\n",
    "    \n",
    "    # Call to quadratic solver library\n",
    "    sol = solvers.qp(P, q, G, h, A, b)\n",
    "    alphas = np.array(sol['x'])\n",
    "    return alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit svm classifier\n",
    "alphas = fitNonLinear(X_train, y_train)\n",
    "\n",
    "# Get support vectors and b\n",
    "cond = (alphas > 1e-4)\n",
    "alpha_sv = alphas[cond]\n",
    "n_sv = len(alpha_sv)\n",
    "xCond = cond.reshape(-1)\n",
    "x_sv = X_train[xCond, :]\n",
    "y_sv = y_train[xCond]\n",
    "K_sv = K[xCond,xCond]\n",
    "\n",
    "b = np.mean(y_sv - K_sv*(np.multiply(alpha_sv, y_sv)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "ym = np.zeros(X_test.shape[0])\n",
    "# Predict the test data\n",
    "Ktest2 = []\n",
    "for j in range(X_test.shape[0]):\n",
    "    x_p = X_test[j]\n",
    "    K_pred=np.zeros(x_sv.shape[0]);\n",
    "    for i in range(x_sv.shape[0]):\n",
    "        K_pred[i] = krbf(x_p, x_sv[i], sigma)\n",
    "    Ktest2.append(K_pred)\n",
    "    ym[j] = np.sign(np.sum(np.multiply(np.multiply(alpha_sv,y_sv), K_pred)) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12,  0],\n",
       "       [ 0, 13]], dtype=int64)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "#Create a confusion matrix to check the accuracy of the algorithm\n",
    "confusion_matrix(y_test, ym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = .4\n",
    "\n",
    "# least square SVM with rbf kernel\n",
    "def fitLS(x, y): \n",
    "    global K\n",
    "    NUM = x.shape[0]\n",
    "    DIM = x.shape[1]\n",
    "    \n",
    "    Y = np.reshape(y, (NUM, 1))\n",
    "    Ym = np.matmul(Y,Y.T)\n",
    "    # we'll solve the dual\n",
    "    # obtain the kernel\n",
    "    K = np.zeros((NUM,NUM))\n",
    "    for i in range(NUM):\n",
    "        for j in range(NUM):\n",
    "            K[i,j] = krbf(x[i], x[j], sigma)\n",
    "\n",
    "    Omega = np.multiply(K, Ym)\n",
    "    onev = np.ones((NUM, 1))\n",
    "    gamma = 1\n",
    "    \n",
    "    yforA = np.reshape(y, (NUM, 1))\n",
    "    \n",
    "    A11 = np.zeros(1).reshape((1,1))\n",
    "    A12 = yforA.T\n",
    "    A21 = yforA\n",
    "    A22 = Omega + np.eye(NUM)/gamma\n",
    "    \n",
    "    A1 = np.hstack((A11, A12))\n",
    "    A2 = np.hstack((A21, A22))\n",
    "\n",
    "    A =  np.vstack((A1, A2))\n",
    "    \n",
    "    B = np.vstack((A11, onev))\n",
    "    \n",
    "    # Solve the linear system of equations\n",
    "    sol = np.linalg.solve(A, B)\n",
    "    b= sol[0]\n",
    "    alpha=sol[1:]\n",
    "    \n",
    "    return {\n",
    "        'b': b,\n",
    "        'alphas': alpha\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit svm classifier\n",
    "alphas = fitLS(X_train, y_train)\n",
    "b = alphas['b']\n",
    "alphas = alphas['alphas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12,  0],\n",
       "       [ 0, 13]], dtype=int64)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ym = np.zeros(X_test.shape[0])\n",
    "# Predict the test data\n",
    "for j in range(X_test.shape[0]):\n",
    "    x_p = X_test[j]\n",
    "    K_pred=np.zeros(X_train.shape[0]);\n",
    "    for i in range(X_train.shape[0]):\n",
    "        K_pred[i] = krbf(x_p, X_train[i], sigma)\n",
    "    ym[j] = np.sign(np.sum(np.multiply(np.multiply(alphas,y_train), K_pred)) + b)\n",
    "\n",
    "#Create a confusion matrix to check the accuracy of the algorithm\n",
    "confusion_matrix(y_test, ym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 15\n",
    "\n",
    "def fitLS_SVR(x, y): \n",
    "    global K\n",
    "    NUM = x.shape[0]\n",
    "    DIM = x.shape[1]\n",
    "    \n",
    "    Y = np.reshape(y, (NUM, 1))\n",
    "    Ym = np.matmul(Y,Y.T)\n",
    "\n",
    "    # we'll solve the dual\n",
    "    # obtain the kernel\n",
    "    K = np.zeros((NUM,NUM))\n",
    "    for i in range(NUM):\n",
    "        for j in range(NUM):\n",
    "            K[i,j] = krbf(x[i], x[j], sigma)\n",
    "\n",
    "    Omega = K\n",
    "    onev = np.ones((NUM, 1))\n",
    "    gamma = 15\n",
    "    \n",
    "    yforA = np.reshape(y, (NUM, 1))\n",
    "\n",
    "    A11 = np.zeros(1).reshape((1,1))\n",
    "    A12 = onev.T\n",
    "    A21 = onev\n",
    "    A22 = Omega + np.eye(NUM)/gamma\n",
    "    \n",
    "    A1 = np.hstack((A11, A12))\n",
    "    A2 = np.hstack((A21, A22))\n",
    "\n",
    "    A =  np.vstack((A1, A2))\n",
    "    \n",
    "    B = np.vstack((A11, yforA))\n",
    "    \n",
    "    # Solve the linear system of equations\n",
    "    sol = np.linalg.solve(A, B)\n",
    "    b= sol[0]\n",
    "    alpha=sol[1:]\n",
    "    \n",
    "    return {\n",
    "        'b': b,\n",
    "        'alphas': alpha\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.load_boston(return_X_y=True)\n",
    "x = preprocessing.scale(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "\n",
    "# fit svm classifier\n",
    "alphas = fitLS_SVR(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = alphas['b']\n",
    "alphas = alphas['alphas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "ym = np.zeros((y_test.shape[0]))\n",
    "\n",
    "for j in range(y_test.shape[0]):\n",
    "    x_p = X_test[j]\n",
    "    K_pred=np.zeros((X_train.shape[0],1));\n",
    "    for i in range(X_train.shape[0]):\n",
    "        K_pred[i] = krbf(x_p, X_train[i], sigma)\n",
    "    ym[j] = np.sum(np.multiply(alphas, K_pred)) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7439106588663464"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, ym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>23.2</td>\n",
       "      <td>25.556329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>23.9</td>\n",
       "      <td>26.984053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>50.0</td>\n",
       "      <td>37.993176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>20.8</td>\n",
       "      <td>17.073516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>21.7</td>\n",
       "      <td>22.011027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>32.0</td>\n",
       "      <td>32.801937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>21.2</td>\n",
       "      <td>22.601385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>32.9</td>\n",
       "      <td>32.419526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>19.5</td>\n",
       "      <td>20.214548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>31.6</td>\n",
       "      <td>32.829239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>26.6</td>\n",
       "      <td>25.130949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>19.6</td>\n",
       "      <td>20.389307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>23.0</td>\n",
       "      <td>22.194998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>18.6</td>\n",
       "      <td>20.062177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>29.8</td>\n",
       "      <td>24.081584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>24.7</td>\n",
       "      <td>25.023050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>22.6</td>\n",
       "      <td>25.189001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>22.2</td>\n",
       "      <td>23.745059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>41.7</td>\n",
       "      <td>40.882883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>27.1</td>\n",
       "      <td>18.659767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>13.1</td>\n",
       "      <td>13.036897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>13.6</td>\n",
       "      <td>13.178064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>22.8</td>\n",
       "      <td>26.044355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>20.2</td>\n",
       "      <td>16.492190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>9.5</td>\n",
       "      <td>11.902765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>16.0</td>\n",
       "      <td>17.702358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>20.4</td>\n",
       "      <td>19.334402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>5.0</td>\n",
       "      <td>7.957195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>16.2</td>\n",
       "      <td>15.982446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>23.3</td>\n",
       "      <td>24.109628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0          1\n",
       "97   23.2  25.556329\n",
       "98   23.9  26.984053\n",
       "99   50.0  37.993176\n",
       "100  20.8  17.073516\n",
       "101  21.7  22.011027\n",
       "102  32.0  32.801937\n",
       "103  21.2  22.601385\n",
       "104  32.9  32.419526\n",
       "105  19.5  20.214548\n",
       "106  31.6  32.829239\n",
       "107  26.6  25.130949\n",
       "108  19.6  20.389307\n",
       "109  23.0  22.194998\n",
       "110  18.6  20.062177\n",
       "111  29.8  24.081584\n",
       "112  24.7  25.023050\n",
       "113  22.6  25.189001\n",
       "114  22.2  23.745059\n",
       "115  41.7  40.882883\n",
       "116  27.1  18.659767\n",
       "117  13.1  13.036897\n",
       "118  13.6  13.178064\n",
       "119  22.8  26.044355\n",
       "120  20.2  16.492190\n",
       "121   9.5  11.902765\n",
       "122  16.0  17.702358\n",
       "123  20.4  19.334402\n",
       "124   5.0   7.957195\n",
       "125  16.2  15.982446\n",
       "126  23.3  24.109628"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataframe = pd.DataFrame(np.array([y_test, ym]).T)\n",
    "\n",
    "dataframe.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
