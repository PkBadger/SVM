{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries and and global variables\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cvxopt import matrix, solvers\n",
    "\n",
    "K = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Loading dataset for classification, scale and split test and train\n",
    "iris = datasets.load_iris()\n",
    "# Filter and conserve tipe 0 and 2 of iris\n",
    "cond = (iris.target != 1)\n",
    "# Preprocess dataset to be used in SVM\n",
    "y = iris.target[cond] - 1\n",
    "y = y.astype('float')\n",
    "x = iris.data[cond].astype('float')\n",
    "x = preprocessing.scale(x)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 1\n",
    "\n",
    "# Custom rbf kernel\n",
    "def krbf(x,y,sigma):\n",
    "    return np.exp(-np.linalg.norm(x - y)**2/(2*sigma**2))\n",
    "\n",
    "# SVM with rbf kernel\n",
    "def fitNonLinear(x, y): \n",
    "    global K\n",
    "    NUM = x.shape[0]\n",
    "    DIM = x.shape[1]\n",
    "    \n",
    "    Y = np.reshape(y, (NUM, 1))\n",
    "    Ym = np.matmul(Y,Y.T)\n",
    "    # we'll solve the dual\n",
    "    # obtain the kernel\n",
    "    K = np.zeros((NUM,NUM))\n",
    "    for i in range(NUM):\n",
    "        for j in range(NUM):\n",
    "            K[i,j] = krbf(x[i], x[j], sigma)\n",
    "    K = np.multiply(K, Ym)\n",
    "    P = matrix(K)\n",
    "    q = matrix(-np.ones((NUM, 1)))\n",
    "    G = matrix(-np.eye(NUM))\n",
    "    h = matrix(np.zeros(NUM))\n",
    "    A = matrix(y.reshape(1, -1))\n",
    "    b = matrix(np.zeros(1))\n",
    "    solvers.options['show_progress'] = False\n",
    "    \n",
    "    # Call to quadratic solver library\n",
    "    sol = solvers.qp(P, q, G, h, A, b)\n",
    "    alphas = np.array(sol['x'])\n",
    "    return alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit svm classifier\n",
    "alphas = fitNonLinear(X_train, y_train)\n",
    "\n",
    "# Get support vectors and b\n",
    "cond = (alphas > 1e-4)\n",
    "alpha_sv = alphas[cond]\n",
    "n_sv = len(alpha_sv)\n",
    "xCond = cond.reshape(-1)\n",
    "x_sv = X_train[xCond, :]\n",
    "y_sv = y_train[xCond]\n",
    "K_sv = K[xCond,xCond]\n",
    "\n",
    "b = np.mean(y_sv - K_sv*(np.multiply(alpha_sv, y_sv)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ym = np.zeros(X_test.shape[0])\n",
    "# Predict the test data\n",
    "Ktest2 = []\n",
    "for j in range(X_test.shape[0]):\n",
    "    x_p = X_test[j]\n",
    "    K_pred=np.zeros(x_sv.shape[0])\n",
    "    for i in range(x_sv.shape[0]):\n",
    "        K_pred[i] = krbf(x_p, x_sv[i], sigma)\n",
    "    Ktest2.append(K_pred)\n",
    "    ym[j] = np.sign(np.sum(np.multiply(np.multiply(alpha_sv,y_sv), K_pred)) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11,  0],\n",
       "       [ 0, 14]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "#Create a confusion matrix to check the accuracy of the algorithm\n",
    "confusion_matrix(y_test, ym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11,  0],\n",
       "       [ 0, 14]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "skSVM = svm.SVC(gamma=0.5)\n",
    "skSVM.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "confusion_matrix(y_test, skSVM.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.10312784,  1.44055745, -0.86678372, -0.91514954],\n",
       "       [-1.27261883,  0.95956999, -1.20256047, -1.02461719],\n",
       "       [-0.74103202,  0.23808879, -0.86678372, -0.69621424],\n",
       "       [-1.3789362 , -2.16684851, -1.05865615, -0.91514954],\n",
       "       [-0.10312784,  2.88351983, -0.96271993, -0.80568189],\n",
       "       [-0.84734938, -0.4833924 , -0.91475182, -1.02461719],\n",
       "       [-1.59157092, -0.4833924 , -1.15459236, -1.13408484],\n",
       "       [-0.63471466,  2.16203864, -0.96271993, -1.13408484],\n",
       "       [ 2.02321941,  1.44055745,  1.53162169,  1.16473578],\n",
       "       [ 0.42845897,  0.47858252,  0.90803629,  1.27420343],\n",
       "       [ 0.00318952, -0.96437986,  0.76413196,  1.38367108],\n",
       "       [ 0.21582425, -2.40734224,  0.71616386,  0.39846224],\n",
       "       [ 1.4916326 , -0.4833924 ,  1.09990872,  0.50792989],\n",
       "       [ 1.70426733, -0.96437986,  1.24381305,  0.83633283],\n",
       "       [ 2.02321941, -0.4833924 ,  1.24381305,  1.27420343],\n",
       "       [ 0.96004579, -1.68586105,  1.09990872,  0.72686519],\n",
       "       [-0.2094452 , -0.96437986,  0.66819575,  0.94580048]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "skSVM.support_vectors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.42518836, 0.46459499, 0.20195655, 0.79411763, 0.56857673,\n",
       "       0.12522993, 0.91242009, 0.8484252 , 0.25589565, 0.78605415,\n",
       "       0.04651846, 0.34285701, 0.37819529, 0.39619176, 0.00727125,\n",
       "       0.01133446, 0.42305865])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_sv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the scikit learn implementation and our implementation, we can see some major differences in the support vectors, this might be because the scikit learn uses a C-Support Vector Classification algorithm, scikit learn doesn't have the algorithm that we implemented, so we cannot do a direct comparison, this might be becuase scikit learn should use advanced algorithms to improve the time complexity of the excecution, in which our algorithm doesn't have good results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
